# 캐시

---

## Cache란?

> 캐시(cache)는 데이터나 갑을 미리 복사해 놓는 임시 장소를 가리킨다
> 
> 속도가 빠른 장치와 느린장치에서 속도차이에 따른 병목 현상을 줄이기 위한 메모리이다.
> 
> Chache에 데이터를 미리 복사해 놓으면 계산이나 접근 시간 없이 더 빠른 속도로 데이터에 접근 할 수있다.
> 결국 Cache란 반복적으로 데이터를 불러오는 경우에 지속적인 DBMS 혹은 서버에 요청하지 안고 Memory에서 데이터를 저장하였다가 불러다 쓰는 것을 의미한다.
> Enterprise 급 Application에서는 DBMS의 부하를 줄이고 성능을 높이기 위해 캐시를 사용한다.


### CPU 캐시
 
- 대량의 메인 메로리 접근을 빠르게 처리하기 위해 CPU 칩 내부나 바로 옆에 탑재하는 작은 메모리이다.
- 메모리 접근 속도가 늘어나는 것에 비해 CPU의 처리 속도가 훨씬 빠르게 늘어나고 있기 때문에, 용량은 작지만 속도가 빠른 CPU 캐시는 현재 마이크로프로세서의 성능에 직접적인 영향을 미친다.

![img.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZdW35%2FbtqCbTDmFj5%2FAKbAUKiWseStnfD1Cd7gqk%2Fimg.png)

L1 : CPU 내부에 존재

L2 : CPU와 RAM 사이에 존재

L3 : 보통 메인보드에 존재한다고 함

Cache는 아래와 같은 경우에 사용을 고려하면 좋다.


- 접근 시간에 비히 원래 데이터를 접근하는 시간이 오래 걸리는 경우(서버의 균일한 API 데이터)


- 반복적으로 동일한 결과를 돌려주는 경우(이미지나 썸네일 등)

## Local Cache vs Global Cache

### [ Local Cache ]


- Local 장비 내에서만 사용되는 캐시로, Local 장비의 Resource를 이용한다.


- Local에서만 작동하기 때문에 속도가 빠르다.


- Local에서만 작동하기 때문에 다른 서버와 데이터 공유가 어렵다.

### [ Global Cache ]


- 여러 서버에서 Cache Server에 접근하여 사용하는 캐시로 분산된 서버에서 데이터를 저장하고 조회할 수 있다.


- 네트워크를 통해 데이터를 가져오므로, Local Cache에 비해 상대적으로 느리다.


- 별도의 Cache서버를 이용하기 때문에 서버 간의 데이터 공유가 쉽다.

## 캐시 메모리 작동 원리

###- 시간 지역성

  for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음


### - 공간 지역성
  A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음

  이처럼 참조 지역성의 원리가 존재한다.

>캐시에 데이터를 저장할 때는, 이러한 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.

---

### 원하는 데이터가 캐시에 존재할 경우 행당 데이터를 반환한다 -> Cache Hit

### 원하는 데이터가 캐시에 존재하지 않을 경우 DBMS 또는 서버에 요청을 해야한다 -> Cache Miss

## 캐시 미스 경우 3가지
###Cold miss
해당 메모리 주소를 처음 불러서 나는 미스

###Conflict miss
캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)

항상 핸드폰과 열쇠를 오른쪽 주머니에 넣고 다니는데, 잠깐 친구가 준 물건을 받느라 손에 들고 있던 핸드폰을 가방에 넣었음. 그 이후 핸드폰을 찾으려 오른쪽 주머니에서 찾는데 없는 상황

###Capacity miss
캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)

캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김

---

## 구조 및 작동 방식

![img.png](https://file.namu.moe/file/8bc9e381797334eb33da66e3ba501be191171b1c5abb113ab52fed45a20084b1c8d2eb5a0ba399d67b38a9d5990b5d5a)

###Direct Mapped Cache

가장 기본적인 구조로, DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식

현재 그림에서는 메모리 공간이 32개(00000~11111)이고, 캐시 메모리 공간은 8개(000~111)인 상황

ex) 00000, 01000, 10000, 11000인 메모리 주소는 000 캐시 메모리 주소에 맵핑

이때 000이 '인덱스 필드', 인덱스 제외한 앞의 나머지(00, 01, 10, 11)를 '태그 필드'라고 한다.

이처럼 캐시메모리는 인덱스 필드 + 태그 필드 + 데이터 필드로 구성된다.

간단하고 빠른 장점이 있지만, Conflict Miss가 발생하는 것이 단점이다. 위 사진처럼 같은 색깔의 데이터를 동시에 사용해야 할 때 발생한다.


###Fully Associative Cache
비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식

저장할 때는 매우 간단하지만, 찾을 때가 문제

조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색해야 한다. CAM이라는 특수한 메모리 구조를 사용해야하지만 가격이 매우 비싸다.


### Set Associative Cache
Direct + Fully 방식이다. 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식이다. Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형이다.

실제로 위 두가지보다 나중에 나온 방식
